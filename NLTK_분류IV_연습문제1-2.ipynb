{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'a': 1, 'b': 1, 'ab': 1, 'c': 1, 'bc': 1, 'abc': 1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix_fdist = nltk.FreqDist()\n",
    "for word in ['','a','ab','abc']:\n",
    "    word = word.lower()\n",
    "    if len(word) == 0:\n",
    "        continue\n",
    "    suffix_fdist[word[-1:]] += 1 if len(word) >= 1 else 0\n",
    "    suffix_fdist[word[-2:]] += 1 if len(word) >= 2 else 0\n",
    "    suffix_fdist[word[-3:]] += 1 if len(word) >= 3 else 0\n",
    "suffix_fdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모범답안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'a': 1, 'b': 1, 'ab': 1, 'c': 1, 'bc': 1, 'abc': 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix_fdist = nltk.FreqDist()\n",
    "for word in ['','a','ab','abc']:\n",
    "    word = word.lower()\n",
    "    if len(word) > 0:\n",
    "        suffix_fdist[word[-1:]] += 1\n",
    "    if len(word) > 1:\n",
    "        suffix_fdist[word[-2:]] += 1\n",
    "    if len(word) > 2:\n",
    "        suffix_fdist[word[-3:]] += 1\n",
    "suffix_fdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 's', 'd', 't', 'n', 'he', 'the', 'y', ',', 'r']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "suffix_fdist = nltk.FreqDist()\n",
    "for word in brown.words():\n",
    "    word = word.lower()\n",
    "    if len(word) > 0:\n",
    "        suffix_fdist[word[-1:]] += 1\n",
    "    if len(word) > 1:\n",
    "        suffix_fdist[word[-2:]] += 1\n",
    "    if len(word) > 2:\n",
    "        suffix_fdist[word[-3:]] += 1\n",
    "common_suffixes = [suffix for suffix, count in suffix_fdist.most_common(100)]\n",
    "common_suffixes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('later', 'RBR'), ('down', 'IN'), ('Earl', 'NP')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pos_features(word):\n",
    "    features={}\n",
    "    for suffix in common_suffixes:\n",
    "        features[f'endswith({suffix})'] = word.lower().endswith(suffix)\n",
    "    return features\n",
    "\n",
    "tagged_words = list(brown.tagged_words(categories='news'))\n",
    "import random\n",
    "random.shuffle(tagged_words)\n",
    "tagged_words[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53078070611636"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets = [(pos_features(n),g) for (n,g) in tagged_words]\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:],featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier,test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5978120338140229"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier1 = nltk.DecisionTreeClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier1,test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "words = tagged_words[:1000]\n",
    "featuresets = [(n,pos_features(n),g) for (n,g) in words]\n",
    "errors_Naive = []\n",
    "errors_Decision = []\n",
    "for n,f,g in featuresets:\n",
    "    naive = classifier.classify(f)\n",
    "    decision = classifier1.classify(f)\n",
    "    if naive != g and decision == g:\n",
    "        errors_Naive.append((n,g,naive,decision))\n",
    "    if naive == g and decision != g:\n",
    "        errors_Decision.append((n,g,naive,decision))\n",
    "print(len(errors_Naive))\n",
    "print(len(errors_Decision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모범답안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_Naive = []\n",
    "for (word,tag) in tagged_words[-1000:]:\n",
    "    guess = classifier.classify(pos_features(word))\n",
    "    guess1 = classifier1.classify(pos_features(word))\n",
    "    if guess != tag and guess1 == tag:\n",
    "        errors_Naive.append((word,tag,guess,guess1))\n",
    "len(errors_Naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_Decision = []\n",
    "for (word, tag) in tagged_words[-1000:]:\n",
    "    guess = classifier.classify(pos_features(word))\n",
    "    guess1 = classifier1.classify(pos_features(word))\n",
    "    if guess == tag and guess1 != tag:\n",
    "        errors_Decision.append((word,tag,guess,guess1))\n",
    "len(errors_Decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nine', 'CD', 'CD', 'NN'),\n",
       " ('careful', 'JJ', 'JJ', 'NN'),\n",
       " ('leg', 'NN', 'NN', 'JJ'),\n",
       " ('has', 'HVZ', 'HVZ', 'CS'),\n",
       " ('Kiowa', 'NP', 'NP', 'AT'),\n",
       " ('earlier', 'JJR', 'JJR', 'NN'),\n",
       " ('it', 'PPO', 'PPO', 'PPS'),\n",
       " ('give', 'VB', 'VB', 'JJ'),\n",
       " ('said', 'VBD', 'VBD', 'NN'),\n",
       " ('Higher', 'JJR', 'JJR', 'AP')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_Decision[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('he', 'PPS', 'AT', 'PPS'),\n",
       " ('at', 'IN', 'CS', 'IN'),\n",
       " ('other', 'AP', 'JJR', 'AP'),\n",
       " ('with', 'IN', 'ABX', 'IN'),\n",
       " ('an', 'AT', 'NP', 'AT'),\n",
       " ('She', 'PPS', 'AT', 'PPS'),\n",
       " ('sixth-sense', 'NN', 'DTS', 'NN'),\n",
       " ('with', 'IN', 'ABX', 'IN'),\n",
       " ('line', 'NN', 'CD', 'NN'),\n",
       " ('at', 'IN', 'CS', 'IN')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_Naive[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
