{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 's', 'd', 't', 'n', 'he', 'the', 'y', ',', 'r']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "suffix_fdist = nltk.FreqDist()\n",
    "for word in brown.words():\n",
    "    word = word.lower()\n",
    "    if len(word) > 0:\n",
    "        suffix_fdist[word[-1:]] += 1\n",
    "    if len(word) > 1:\n",
    "        suffix_fdist[word[-2:]] += 1\n",
    "    if len(word) > 2:\n",
    "        suffix_fdist[word[-3:]] += 1\n",
    "common_suffixes = [suffix for suffix, count in suffix_fdist.most_common(100)]\n",
    "common_suffixes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('buss', 'NN'), ('and', 'CC'), ('Joseph', 'NP')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pos_features(word):\n",
    "    features={}\n",
    "    for suffix in common_suffixes:\n",
    "        features[f'endswith({suffix})'] = word.lower().endswith(suffix)\n",
    "    return features\n",
    "\n",
    "tagged_words = list(brown.tagged_words(categories='news'))\n",
    "import random\n",
    "random.shuffle(tagged_words)\n",
    "tagged_words[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5262058677274988"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets = [(pos_features(n),g) for (n,g) in tagged_words]\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:],featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier,test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             endswith(.) = True                . : NN     =   7115.5 : 1.0\n",
      "            endswith(of) = True            IN-TL : NN     =   6278.4 : 1.0\n",
      "            endswith(es) = True              DOZ : IN     =   6214.6 : 1.0\n",
      "            endswith(he) = True            AT-TL : NN     =   4263.8 : 1.0\n",
      "           endswith(are) = True              BER : NP     =   4108.2 : 1.0\n",
      "            endswith(ot) = True                * : NP     =   4106.5 : 1.0\n",
      "           endswith(ere) = True              BED : NP     =   4105.9 : 1.0\n",
      "           endswith(ave) = True               HV : NN     =   3377.1 : 1.0\n",
      "             endswith(a) = True            NN-NC : IN     =   3335.1 : 1.0\n",
      "            endswith(th) = True              ABX : NNS    =   3032.8 : 1.0\n",
      "             endswith(h) = True              ABX : NNS    =   3032.8 : 1.0\n",
      "           endswith(hat) = True               CS : NN     =   2775.8 : 1.0\n",
      "           endswith(uld) = True            MD-HL : NP     =   2400.6 : 1.0\n",
      "            endswith(ne) = True            FW-CD : NNS    =   2292.0 : 1.0\n",
      "            endswith(om) = True              WPO : JJ     =   2232.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5952262555942317"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier1 = nltk.DecisionTreeClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier1,test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if endswith(the) == False: return 'NN'\n",
      "if endswith(the) == True: return 'AT'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classifier1.pseudocode(depth=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if endswith(the) == False: \n",
      "  if endswith(,) == False: return 'NN'\n",
      "  if endswith(,) == True: return ','\n",
      "if endswith(the) == True: return 'AT'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classifier1.pseudocode(depth=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if endswith(the) == False: \n",
      "  if endswith(,) == False: \n",
      "    if endswith(s) == False: return 'NN'\n",
      "    if endswith(s) == True: return 'NNS'\n",
      "  if endswith(,) == True: return ','\n",
      "if endswith(the) == True: return 'AT'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classifier1.pseudocode(depth=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if endswith(the) == False: \n",
      "  if endswith(,) == False: \n",
      "    if endswith(s) == False: \n",
      "      if endswith(.) == False: \n",
      "        if endswith(of) == False: \n",
      "          if endswith(and) == False: return 'NN'\n",
      "          if endswith(and) == True: return 'CC'\n",
      "        if endswith(of) == True: return 'IN'\n",
      "      if endswith(.) == True: return '.'\n",
      "    if endswith(s) == True: \n",
      "      if endswith(is) == False: \n",
      "        if endswith(was) == False: \n",
      "          if endswith(as) == False: return 'NNS'\n",
      "          if endswith(as) == True: return 'CS'\n",
      "        if endswith(was) == True: return 'BEDZ'\n",
      "      if endswith(is) == True: \n",
      "        if endswith(his) == False: return 'BEZ'\n",
      "        if endswith(his) == True: return 'PP$'\n",
      "  if endswith(,) == True: return ','\n",
      "if endswith(the) == True: return 'AT'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classifier1.pseudocode(depth=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 맥락을 이용한 POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_features(sentence, i):\n",
    "    features = {\n",
    "        'suffix(1)': sentence[i][-1:],\n",
    "        'suffix(2)': sentence[i][-2:],\n",
    "        'suffix(3)': sentence[i][-3:]\n",
    "    }\n",
    "    if i==0:\n",
    "        features['prev-word'] = '<START>'\n",
    "    else:\n",
    "        features['prev-word'] = sentence[i-1]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n"
     ]
    }
   ],
   "source": [
    "print(brown.sents()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'suffix(1)': 'e', 'suffix(2)': 'he', 'suffix(3)': 'The', 'prev-word': '<START>'}\n"
     ]
    }
   ],
   "source": [
    "print(pos_features(brown.sents()[0],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'suffix(1)': 'n', 'suffix(2)': 'on', 'suffix(3)': 'ton', 'prev-word': 'The'}\n"
     ]
    }
   ],
   "source": [
    "print(pos_features(brown.sents()[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'suffix(1)': 'y', 'suffix(2)': 'ty', 'suffix(3)': 'nty', 'prev-word': 'Fulton'}\n"
     ]
    }
   ],
   "source": [
    "print(pos_features(brown.sents()[0],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'suffix(1)': 'd', 'suffix(2)': 'nd', 'suffix(3)': 'and', 'prev-word': 'County'}\n"
     ]
    }
   ],
   "source": [
    "print(pos_features(brown.sents()[0],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('For', 'IN-HL'), ('crucial', 'JJ-HL'), ('encounter', 'NN-HL')]]\n"
     ]
    }
   ],
   "source": [
    "tagged_sents = list(brown.tagged_sents(categories='news'))\n",
    "import random\n",
    "random.shuffle(tagged_sents)\n",
    "print(tagged_sents[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = []\n",
    "for tagged_sent in tagged_sents:\n",
    "    untagged_sent = nltk.tag.untag(tagged_sent)\n",
    "    for i, (word,tag) in enumerate(tagged_sent):\n",
    "        featuresets.append((pos_features(untagged_sent,i),tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'suffix(1)': 'r', 'suffix(2)': 'or', 'suffix(3)': 'For', 'prev-word': '<START>'}, 'IN-HL'), ({'suffix(1)': 'l', 'suffix(2)': 'al', 'suffix(3)': 'ial', 'prev-word': 'For'}, 'JJ-HL'), ({'suffix(1)': 'r', 'suffix(2)': 'er', 'suffix(3)': 'ter', 'prev-word': 'crucial'}, 'NN-HL')]\n"
     ]
    }
   ],
   "source": [
    "print(featuresets[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7795126802585778"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int(len(featuresets)*0.1)\n",
    "train_set, test_set = featuresets[size:],featuresets[:size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier,test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7694679264047738"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier1 = nltk.DecisionTreeClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier1,test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 함수 untag, 함수 enumerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n"
     ]
    }
   ],
   "source": [
    "temp = brown.tagged_sents()[0]\n",
    "print(nltk.tag.untag(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, ('The', 'AT')), (1, ('Fulton', 'NP-TL')), (2, ('County', 'NN-TL')), (3, ('Grand', 'JJ-TL')), (4, ('Jury', 'NN-TL')), (5, ('said', 'VBD')), (6, ('Friday', 'NR')), (7, ('an', 'AT')), (8, ('investigation', 'NN')), (9, ('of', 'IN')), (10, (\"Atlanta's\", 'NP$')), (11, ('recent', 'JJ')), (12, ('primary', 'NN')), (13, ('election', 'NN')), (14, ('produced', 'VBD')), (15, ('``', '``')), (16, ('no', 'AT')), (17, ('evidence', 'NN')), (18, (\"''\", \"''\")), (19, ('that', 'CS')), (20, ('any', 'DTI')), (21, ('irregularities', 'NNS')), (22, ('took', 'VBD')), (23, ('place', 'NN')), (24, ('.', '.'))]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in enumerate(temp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
